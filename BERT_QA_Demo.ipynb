{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_QA_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWsTB9I9j0Zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019 The BERT-QA Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# For more information, see https://github.com/artitw/BERT_QA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTy4MUDMPYkl",
        "colab_type": "code",
        "outputId": "bec41f50-962e-4cfd-9bdf-0f5109f199a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "## Installation\n",
        "pip install --upgrade bert_qa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert_qa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/cc/aa7daebc9701c8559da8efaeab3e6b95640e03b5f4bc363ae68fed6532c7/bert_qa-0.0.6-py3-none-any.whl (116kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 61kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tensorflow-gpu>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from bert_qa) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bert_qa) (0.1.85)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from bert_qa) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from bert_qa) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=2.0.0->bert_qa) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu>=2.0.0->bert_qa) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu>=2.0.0->bert_qa) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu>=2.0.0->bert_qa) (0.4.8)\n",
            "Installing collected packages: bert-qa\n",
            "  Found existing installation: bert-qa 0.0.5\n",
            "    Uninstalling bert-qa-0.0.5:\n",
            "      Successfully uninstalled bert-qa-0.0.5\n",
            "Successfully installed bert-qa-0.0.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bert_qa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Cy5mK_yGSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### download SQuAD data\n",
        "%%bash\n",
        "wget -q https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "wget -q https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7uvFpaRyT8P",
        "colab_type": "code",
        "outputId": "4f1f8978-136f-4d44-ebfd-43f0a57d30a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "### download pre-trained model\n",
        "%%bash\n",
        "wget -q https://storage.googleapis.com/cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12.tar.gz\n",
        "tar -xvzf uncased_L-12_H-768_A-12.tar.gz\n",
        "mv -f home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12 ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/\n",
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "home/hongkuny/public/pretrained_models/keras_bert/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWZGDv1sTEt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### import library\n",
        "from bert_qa import squad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS6k3PpbncgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### initialize\n",
        "qa = squad.SQuAD()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0a4RDuXVLEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### pre-process data\n",
        "qa.preprocess_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT6_6dxSDH4O",
        "colab_type": "code",
        "outputId": "385dbb01-c238-4d61-f0f8-44ed1f78d43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "### finetune\n",
        "qa.fit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler\" was not an Input tensor, it was generated by layer input_mask.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_mask:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler\" was not an Input tensor, it was generated by layer input_mask.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_mask:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler\" was not an Input tensor, it was generated by layer input_type_ids.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_type_ids:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler\" was not an Input tensor, it was generated by layer input_type_ids.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_type_ids:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYEAwqFDIY4",
        "colab_type": "code",
        "outputId": "59e7f542-3b93-4b61-f5b7-aa2995cadddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "### predict\n",
        "qa.predict()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler_2\" was not an Input tensor, it was generated by layer input_mask.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_mask_2:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler_2\" was not an Input tensor, it was generated by layer input_mask.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_mask_2:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler_2\" was not an Input tensor, it was generated by layer input_type_ids.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_type_ids_2:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:BertSpanLabeler inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"bert_span_labeler_2\" was not an Input tensor, it was generated by layer input_type_ids.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_type_ids_2:0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myp8o8eKiYX-",
        "colab_type": "code",
        "outputId": "d0632e2b-5933-4a1f-80ec-805d36effe29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### evaluate\n",
        "import json\n",
        "pred_data = json.load(open('model/predictions.json'))\n",
        "dev_data = json.load(open('dev-v1.1.json'))['data']\n",
        "qa.evaluate(dev_data, pred_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 0.510879848628193, 'f1': 2.233702895064975}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}